{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a04c1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytest\n",
    "from tensorly import tenalg\n",
    "tenalg.set_backend(\"einsum\")\n",
    "\n",
    "# Parameterize use of torch_scatter if it is built\n",
    "try: \n",
    "    from torch_scatter import segment_csr\n",
    "    use_torch_scatter = [True, False]\n",
    "except:\n",
    "    use_torch_scatter = [False]\n",
    "    print(\"Install torch_scatter to use it in GINO., your version of torch is:\", torch.__version__)\n",
    "\n",
    "try:\n",
    "    import open3d\n",
    "except:\n",
    "    print(\"Install open3d to use GINO.\")\n",
    "from neuralop.models.gino import GINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6adfd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# neuralop imports\n",
    "from neuralop.layers.gno_block import GNOBlock\n",
    "from neuralop.layers.channel_mlp import ChannelMLP\n",
    "from neuralop.layers.fno_block import FNOBlocks\n",
    "\n",
    "# data set imports\n",
    "import dataset_utils as du\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbf7213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 95, Validation dataset size: 5\n"
     ]
    }
   ],
   "source": [
    "B = 1 # must use batch size of 1 for GNOBlock\n",
    "\n",
    "# load dataset\n",
    "dataset = du.SDFDataset(\"./cars100\")\n",
    "train_percent = 0.95 \n",
    "\n",
    "# split dataset into training and validation sets\n",
    "train_size = int(train_percent * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=B, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=B, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}, Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a85874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_geom shape: torch.Size([1000, 3]), latent_queries shape: torch.Size([1, 64, 64, 64, 3]), features shape: torch.Size([1, 1000, 1]), output_queries shape: torch.Size([1000, 3]), output_labels shape: torch.Size([1, 1000, 1])\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch, grid_size, query_size, input_size):\n",
    "    # y\n",
    "    input_geom = batch[:, :input_size, :3]  # x, y, z coordinates\n",
    "    input_geom = input_geom.squeeze(0) \n",
    "\n",
    "    # x (grid points in 3D space) generate 64x64x64 grid with bounds [-1, 1] in each dimension\n",
    "    coords = torch.linspace(-1.0, 1.0, grid_size) \n",
    "    x, y, z = torch.meshgrid(coords, coords, coords, indexing='ij') \n",
    "    latent_queries = torch.stack((x, y, z), dim=-1)\n",
    "    # transform to match batch size\n",
    "    latent_queries = latent_queries.repeat(B, 1, 1, 1, 1)  # Repeat for batch size B\n",
    "    latent_queries = latent_queries\n",
    "\n",
    "    # f_y\n",
    "    features = batch[:, :input_size, 3]  # features (e.g., colors, normals)\n",
    "    features = features.unsqueeze(-1)\n",
    "\n",
    "    # queries (for now just the same as input_geom)\n",
    "    output_queries = input_geom.clone().squeeze(0)[:query_size,:]  # !For now, just use first 1000 points of input_geom as output_queries\n",
    "    output_labels = features.clone()[:query_size,:]  # !For now, just use first 1000 points of features as output_labels\n",
    "    return input_geom, latent_queries, features, output_queries, output_labels\n",
    "\n",
    "# test\n",
    "batch = next(iter(train_loader))\n",
    "input_geom, latent_queries, features, output_queries, output_labels = process_batch(batch, grid_size=64, query_size=1000, input_size=1000)\n",
    "print(f'input_geom shape: {input_geom.shape}, latent_queries shape: {latent_queries.shape}, features shape: {features.shape}, output_queries shape: {output_queries.shape}, output_labels shape: {output_labels.shape}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cf315c",
   "metadata": {},
   "source": [
    "Test and train prebuilt GINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "model = GINO(\n",
    "        in_channels=1,\n",
    "        out_channels=1\n",
    "    ).to(device)\n",
    "\n",
    "# process the batch\n",
    "input_geom, latent_queries, features, output_queries, output_labels = process_batch(batch, grid_size=64, query_size=1000, input_size=1000)\n",
    "\n",
    "out = model(x=features, input_geom=input_geom, latent_queries=latent_queries, output_queries=output_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45a35fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 95/95 [01:47<00:00,  1.13s/it]\n",
      "Training Epochs:  20%|██        | 1/5 [01:47<07:09, 107.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.0329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 95/95 [01:46<00:00,  1.12s/it]\n",
      "Training Epochs:  40%|████      | 2/5 [03:33<05:20, 106.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 95/95 [01:48<00:00,  1.14s/it]\n",
      "Training Epochs:  60%|██████    | 3/5 [05:22<03:35, 107.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.0255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 95/95 [01:47<00:00,  1.13s/it]\n",
      "Training Epochs:  80%|████████  | 4/5 [07:09<01:47, 107.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches: 100%|██████████| 95/95 [01:45<00:00,  1.11s/it]\n",
      "Training Epochs: 100%|██████████| 5/5 [08:54<00:00, 106.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.0256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "model = GINO(\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        gno_use_open3d=True,         \n",
    "        gno_use_torch_scatter=True).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()  # Mean Squared Error loss for SDF regression\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=\"Training Batches\"):\n",
    "        batch = batch.to(device)  # Move batch to device\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        # process the batch\n",
    "        input_geom, latent_queries, features, output_queries, output_labels = process_batch(batch, grid_size=10, query_size=1000, input_size=1000)\n",
    "        \n",
    "        out = model(x=features, input_geom=input_geom, latent_queries=latent_queries, output_queries=output_queries)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(out, output_labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
