{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb563b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ModelNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, Linear, PointNetConv, fps, global_max_pool, radius\n",
    "from torch_geometric.typing import WITH_TORCH_CLUSTER\n",
    "\n",
    "if not WITH_TORCH_CLUSTER:\n",
    "    quit(\"This example requires 'torch-cluster'\")\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc7235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data set imports\n",
    "import dataset_utils as du\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "B = 1\n",
    "\n",
    "# load dataset\n",
    "dataset = du.SDFDataset(\"./cars995\")\n",
    "train_percent = 0.9755\n",
    "\n",
    "\n",
    "# split dataset into training and validation sets\n",
    "train_size = int(train_percent * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=B, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=B, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}, Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7ffb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch, np_in=2048, np_q=15000):\n",
    "    B, N, _ = batch.shape\n",
    "    assert B == 1, \"Batch size must be 1 for now.\"\n",
    "    \n",
    "    # use surface points\n",
    "    # surface_points = batch[batch[:, :, 3] == 0]\n",
    "    idx = torch.randperm(N)[:np_in]\n",
    "    pos = batch[:, idx, :3] # input positions (B, N, 3) -> (N, 3). this is what fps expects\n",
    "    x = batch[0, idx, 3].unsqueeze(-1)\n",
    "    \n",
    "    idx = torch.randperm(N)[:np_q]\n",
    "    query_pos = batch[:, idx, :3] # query positions\n",
    "    query_sdf = batch[:, idx, 3] # SDF values\n",
    "    \n",
    "    batch_vec = torch.zeros(np_in, dtype=torch.long) # batch vector for input points\n",
    "    \n",
    "    return x.to(device), pos.contiguous().squeeze(0).to(device), batch_vec.contiguous().squeeze(0).to(device), query_pos.squeeze(0).to(device), query_sdf.squeeze(0).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432cb988",
   "metadata": {},
   "source": [
    "Define Layers and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0185a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SAModule and GlobalSModule code is taken from the official pytorch_geometric examples\n",
    "# See https://github.com/pyg-team/pytorch_geometric/blob/master/examples/pointnet2_classification.py\n",
    "\n",
    "class SAModule(torch.nn.Module):\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "                          max_num_neighbors=128)\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class GlobalSAModule(torch.nn.Module):\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        x = self.nn(torch.cat([x, pos], dim=1))\n",
    "        x = global_max_pool(x, batch)\n",
    "        pos = pos.new_zeros((x.size(0), 3))\n",
    "        batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        self.sa1_module = SAModule(0.5, 0.2, MLP([4, 64, 64, 128]))\n",
    "        self.sa2_module = SAModule(0.25, 0.5, MLP([128 + 3, 128, 128, 256]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
    "\n",
    "        self.encode = MLP([1024, 512], dropout=0.4, norm=None) # learn global features -> reduce to 512\n",
    "\n",
    "        self.mlp_mu = MLP([512, 512], dropout=0.2, norm=None) # get mu\n",
    "        self.mlp_logvar = MLP([512, 512], dropout=0.2, norm=None) # get logvar\n",
    "\n",
    "        self.sdf1 = MLP([512 + 3, 256, 128], norm=None)\n",
    "        self.sdf2 = MLP([128 + 3, 64, 1], norm=None)\n",
    "        \n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        epsilon = torch.randn_like(std) # std just gives dimension of tensor to give back\n",
    "        return mu + epsilon * std\n",
    "\n",
    "\n",
    "    def encoder(self, x, pos, batch):\n",
    "        # encode shape\n",
    "        sa0_out = (x, pos, batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "        return sa3_out # x latent encoding from pointnet\n",
    "\n",
    "\n",
    "    def vae(self, x):\n",
    "        x = self.encode(x)\n",
    "        mu = self.mlp_mu(x) # [1, 512]\n",
    "        logvar = self.mlp_logvar(x) # [1, 512]\n",
    "        z = self.reparametrize(mu, logvar) # [1, 512]\n",
    "        return z, mu, logvar\n",
    "\n",
    "\n",
    "    def decoder(self, x, query_pos):\n",
    "        x = torch.cat((x.repeat(query_pos.shape[0], 1), query_pos), dim=-1) # concatenate encoded shape with query positions) # [B, np_q, 515]\n",
    "        x = self.sdf1(x) # [B, np_q, 128]\n",
    "        x = torch.cat((x, query_pos), dim=-1) # [B, np_q, 131]\n",
    "        x = self.sdf2(x) # [B, np_q, 1]\n",
    "        out = torch.tanh(x) # [B, np_q, 1]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward(self, x, pos, batch, query_pos):\n",
    "        # encode\n",
    "        x, pos, batch = self.encoder(x, pos, batch)\n",
    "\n",
    "        # vae\n",
    "        x, mu, logvar = self.vae(x)\n",
    "       \n",
    "        # decoder\n",
    "        out = self.decoder(x, query_pos)\n",
    "\n",
    "        return out, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ab322",
   "metadata": {},
   "source": [
    "Define Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b751b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eikonal_loss(out, query_pos):\n",
    "    grads = torch.autograd.grad(out.sum(), query_pos, create_graph=True)[0]\n",
    "    loss = ((grads.norm(2, dim=1) - 1).square()).mean()\n",
    "    return loss\n",
    "\n",
    "def compute_loss(out, query_pos, query_sdf, mu, logvar, w_eik=0.001, w_kl=0.001):\n",
    "    loss_mse = F.mse_loss(out, query_sdf)\n",
    "    loss_eik = eikonal_loss(out, query_pos)\n",
    "    loss_kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # KL Divergence loss for latent distribution\n",
    "\n",
    "    total_loss = loss_mse + w_eik * loss_eik + w_kl * loss_kl\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def compute_loss_simple(out, query_sdf, mu, logvar):\n",
    "    loss_kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # KL Divergence loss for latent distribution\n",
    "    loss_mse = F.mse_loss(out, query_sdf)\n",
    "\n",
    "    return F.mse_loss(out, query_sdf) + 0.01*loss_kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model = Net().to(device)\n",
    "model.load_state_dict(torch.load('pointnet_vaesdf_simple.pth', map_location=device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(f'Batch shape: {batch.shape}')\n",
    "x, pos, batch, query_pos, query_sdf = process_batch(batch)\n",
    "query_pos.requires_grad = True\n",
    "print(f'pos shape: {pos.shape}, query_pos shape: {query_pos.shape}, query_sdf shape: {query_sdf.shape}, x shape: {x.shape}')\n",
    "\n",
    "print(f'pos shape: {pos.shape}')\n",
    "# forward pass\n",
    "output, mu, logvar = model(x, pos, batch, query_pos)\n",
    "# print output shape\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "\n",
    "loss = compute_loss(output.squeeze(-1), query_pos, query_sdf, mu, logvar)\n",
    "print(f'Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_validation():\n",
    "    model.eval()\n",
    "    batch = next(iter(val_loader))\n",
    "    batch = batch[0,:,:].unsqueeze(0) # just take first pointcloud from batch\n",
    "    \n",
    "    x, pos, batch, query_pos, query_sdf = process_batch(batch)\n",
    "    query_pos.requires_grad = True\n",
    "    \n",
    "    output, mu, logvar = model(x, pos, batch, query_pos)\n",
    "\n",
    "    prediction = torch.cat((query_pos, output), dim=-1).detach().cpu()  # (1024, 3 + 1)\n",
    "    truth = torch.cat((query_pos, query_sdf.unsqueeze(-1)), dim=-1).detach().cpu()  # (1024, 3 + 1)\n",
    "    \n",
    "\n",
    "    print(\"MODEL\")\n",
    "    du.visualize_sdf_3d(prediction.squeeze(0))\n",
    "    du.visualize_sdf_2d(prediction.squeeze(0))\n",
    "    print(\"TRUTH\")\n",
    "    du.visualize_sdf_3d(truth.squeeze(0))\n",
    "    du.visualize_sdf_2d(truth.squeeze(0))\n",
    "\n",
    "    loss = compute_loss(output.squeeze(-1), query_pos, query_sdf, mu, logvar)  # L1 loss for SDF prediction\n",
    "    print(\"Validation Loss: {:.4f}\".format(loss.item()))\n",
    "\n",
    "    return loss\n",
    "\n",
    "show_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d934ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 1500\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0   \n",
    "    for batch in train_loader:\n",
    "        x, pos, batch, query_pos, query_sdf = process_batch(batch)\n",
    "        query_pos.requires_grad = True\n",
    "        optimizer.zero_grad()\n",
    "        out, mu, logvar = model(x, pos, batch, query_pos)\n",
    "        loss = compute_loss(out.squeeze(-1), query_pos, query_sdf, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    mean_loss = total_loss / n_batches\n",
    "    return mean_loss\n",
    "\n",
    "\n",
    "log_path = 'loss_log_simple.txt'\n",
    "with open(log_path, 'w') as f:\n",
    "    f.write('epoch,train_loss\\n')\n",
    "\n",
    "    for epoch in tqdm(range(1, EPOCHS+1)):\n",
    "        loss = train(epoch)                     \n",
    "\n",
    "        # write to file\n",
    "        f.write(f'{epoch},{loss:.4f}\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # 5) (Optional) console feedback every 20 epochs\n",
    "        if epoch % 1 == 0:\n",
    "            print(f'Epoch {epoch:4d} | Loss: {loss:.4f}')\n",
    "        if epoch % 20 == 0:\n",
    "            show_validation()\n",
    "            torch.save(model.state_dict(), 'pointnet_vaesdf_simple.pth') # save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0959bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('pointnet_vaesdf_simple.pth', map_location=device))\n",
    "\n",
    "show_validation()  # show validation results after training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
