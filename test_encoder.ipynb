{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9189a0",
   "metadata": {},
   "source": [
    "# **Test Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001d8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import torch\n",
    "\n",
    "# import custom modules\n",
    "import dataset_utils \n",
    "import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2466f",
   "metadata": {},
   "source": [
    "**Load and prepare dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4369d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters\"\"\"\n",
    "# training and setup\n",
    "train_percent = 0.8\n",
    "batch_size = 10 #(B)\n",
    "lr = 0.001\n",
    "epochs = 1\n",
    "\n",
    "# model parameters\n",
    "num_inputs = 2048 # number of input points (N)\n",
    "num_latents = 512 # number of latent points (N')\n",
    "dim = 512 # dimension of point embeddings (D)\n",
    "num_query_points = 512 # number of query points (M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a4585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = dataset_utils.SDFDataset(\"./cars100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1536d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 100, Train size: 80, Validation size: 20\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# get set sizes for train and validation splits\n",
    "train_size = int(train_percent * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "print(f\"Dataset size: {len(dataset)}, Train size: {train_size}, Validation size: {val_size}\")\n",
    "\n",
    "# split dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51a8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([10, 50000, 4])\n"
     ]
    }
   ],
   "source": [
    "# Get one batch from the train_loader\n",
    "for batch in train_loader:\n",
    "    print(\"Batch shape:\", batch.shape)\n",
    "    break  # only print the first batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebb27d",
   "metadata": {},
   "source": [
    "**Setup model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeaa8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# initialize model and optimizer\n",
    "model = layers.KLAutoEncoder(num_inputs=num_inputs, num_latents=num_latents, dim = dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: torch.Size([10, 512, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# # from importlib import reload\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# # reload(t)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m t\u001b[38;5;241m.\u001b[39mtrain(model, train_loader, val_loader, optimizer, device, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\trainer.py:7\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, optimizer, device, num_epochs, kl_weight)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, train_loader, val_loader, optimizer, device, num_epochs, kl_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 7\u001b[0m         train_one_epoch(model, train_loader, optimizer, device, kl_weight)\n\u001b[0;32m      8\u001b[0m         val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\trainer.py:35\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, data_loader, optimizer, device, kl_weight, points_used, num_query_points)\u001b[0m\n\u001b[0;32m     31\u001b[0m query_sdf \u001b[38;5;241m=\u001b[39m query_points[:, :, \u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)   \u001b[38;5;66;03m# shape [B, query_points]\u001b[39;00m\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 35\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(sample_pos, query_pos)\n\u001b[0;32m     37\u001b[0m predicted_sdfs \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdf\u001b[39m\u001b[38;5;124m'\u001b[39m]   \u001b[38;5;66;03m# (B, N_query)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl\u001b[39m\u001b[38;5;124m'\u001b[39m]            \u001b[38;5;66;03m# (B, )\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\layers.py:347\u001b[0m, in \u001b[0;36mKLAutoEncoder.forward\u001b[1;34m(self, pc, queries)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pc, queries):\n\u001b[0;32m    345\u001b[0m     kl, x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(pc)\n\u001b[1;32m--> 347\u001b[0m     o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode(x, queries)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;66;03m# return o.squeeze(-1), kl\u001b[39;00m\n\u001b[0;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msdf\u001b[39m\u001b[38;5;124m'\u001b[39m: o, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkl\u001b[39m\u001b[38;5;124m'\u001b[39m: kl}\n",
      "File \u001b[1;32mc:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\layers.py:331\u001b[0m, in \u001b[0;36mKLAutoEncoder.decode\u001b[1;34m(self, x, queries)\u001b[0m\n\u001b[0;32m    328\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m self_attn, self_ff \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 331\u001b[0m     x \u001b[38;5;241m=\u001b[39m self_attn(x) \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m    332\u001b[0m     x \u001b[38;5;241m=\u001b[39m self_ff(x) \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# cross attend from decoder queries to latents\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\layers.py:60\u001b[0m, in \u001b[0;36mPreNorm.forward\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     normed_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_context(context)\n\u001b[0;32m     58\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(context \u001b[38;5;241m=\u001b[39m normed_context)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lukas\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\layers.py:127\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x, context, mask)\u001b[0m\n\u001b[0;32m    123\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m t: rearrange(t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb n (h d) -> (b h) n d\u001b[39m\u001b[38;5;124m'\u001b[39m, h \u001b[38;5;241m=\u001b[39m h), (q, k, v))\n\u001b[0;32m    125\u001b[0m sim \u001b[38;5;241m=\u001b[39m einsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb i d, b j d -> b i j\u001b[39m\u001b[38;5;124m'\u001b[39m, q, k) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exists(mask):\n\u001b[0;32m    128\u001b[0m     mask \u001b[38;5;241m=\u001b[39m rearrange(mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb ... -> b (...)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    129\u001b[0m     max_neg_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfinfo(sim\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmax\n",
      "File \u001b[1;32mc:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\layers.py:15\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(val)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DropPath\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\" Utility functions\"\"\"\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexists\u001b[39m(val):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(val, d):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import trainer as t\n",
    "# # from importlib import reload\n",
    "# # reload(t)\n",
    "t.train(model, train_loader, val_loader, optimizer, device, num_epochs=epochs, points_used = num_inputs, num_query_points=num_query_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f6c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def test_model(example):\n",
    "    # Random indices: shape [B, points_used]\n",
    "    samples_idx = torch.randperm(example.shape[0])[:2048]\n",
    "    query_idx = torch.randperm(example.shape[0])[:10000]\n",
    "\n",
    "    samples = example[samples_idx].unsqueeze(0) # [1, 2048, 4]\n",
    "    queries = example[query_idx].unsqueeze(0) # [1, 2048, 4]\n",
    "    # queries = example.unsqueeze(0)\n",
    "\n",
    "    sample_pos = samples[:, :, :3].to(device) # [B, points_used, 3]\n",
    "    query_pos = queries[:, :, :3].to(device) # [B, points_used, 3]\n",
    "\n",
    "    outputs = model(sample_pos, query_pos)\n",
    "    sdf_values = outputs['sdf'].unsqueeze(-1)  # add extra dimension at the end, [1, 512, 1]\n",
    "\n",
    "    combined = torch.cat([query_pos, sdf_values], dim=-1)  # shape [1, 512, 4]\n",
    "\n",
    "    return combined\n",
    "\n",
    "def totally_random(example):\n",
    "    query_idx = torch.randperm(example.shape[0])[:10000]\n",
    "    queries = example[query_idx].unsqueeze(0) # [1, 2048, 4]\n",
    "    query_pos = queries[:, :, :3].to(device) # [B, points_used, 3]\n",
    "\n",
    "    sdf_values = torch.rand(1, 10000, 1) - 0.15\n",
    "\n",
    "    combined = torch.cat([query_pos.cpu(), sdf_values.cpu()], dim=-1)  # shape [1, 512, 4]\n",
    "    return combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\dataset_utils.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.path, self.files[idx]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled_pc_embeddings shape: torch.Size([1, 512, 512]), pc_embeddings shape: torch.Size([1, 2048, 512])\n",
      "TRUE\n"
     ]
    }
   ],
   "source": [
    "import dataset_utils\n",
    "model.eval()\n",
    "example = val_dataset[torch.randint(0, 20, (1,)).item()]\n",
    "\n",
    "pred = test_model(example).squeeze(0).cpu()\n",
    "rand = totally_random(example).squeeze(0)\n",
    "\n",
    "# dataset_utils.visualize_sdf_2d(pred.detach().cpu())\n",
    "print(\"TRUE\")\n",
    "dataset_utils.visualize_sdf_3d(example)\n",
    "dataset_utils.visualize_sdf_2d(example)\n",
    "print(\"MODEL\")\n",
    "dataset_utils.visualize_sdf_3d(pred.detach().cpu())\n",
    "dataset_utils.visualize_sdf_2d(pred.detach().cpu(), tolerance=0.1)\n",
    "print(\"TOTALLY RANDOM\")\n",
    "dataset_utils.visualize_sdf_3d(rand)\n",
    "dataset_utils.visualize_sdf_2d(rand)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
