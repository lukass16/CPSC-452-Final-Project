{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d9189a0",
   "metadata": {},
   "source": [
    "# **Test Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001d8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import torch\n",
    "\n",
    "# import custom modules\n",
    "import dataset_utils \n",
    "import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d2466f",
   "metadata": {},
   "source": [
    "**Load and prepare dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4369d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters\"\"\"\n",
    "# training and setup\n",
    "train_percent = 0.8\n",
    "batch_size = 10 #(B)\n",
    "lr = 0.001\n",
    "epochs = 10\n",
    "\n",
    "# model parameters\n",
    "num_inputs = 10000 # number of input points (N)\n",
    "num_latents = 500 # number of latent points (N')\n",
    "dim = 500 # dimension of point embeddings (D)\n",
    "num_query_points = 1000 # number of query points (M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624a4585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset = dataset_utils.SDFDataset(\"./cars100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1536d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 100, Train size: 80, Validation size: 20\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# get set sizes for train and validation splits\n",
    "train_size = int(train_percent * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "print(f\"Dataset size: {len(dataset)}, Train size: {train_size}, Validation size: {val_size}\")\n",
    "\n",
    "# split dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create data loaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ebb27d",
   "metadata": {},
   "source": [
    "**Setup model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eeaa8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# initialize model and optimizer\n",
    "model = layers.KLAutoEncoder(num_inputs=num_inputs, num_latents=num_latents, dim = dim, queries_dim=dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e3166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import trainer as t\n",
    "# # from importlib import reload\n",
    "# # reload(t)\n",
    "t.train(model, train_loader, val_loader, optimizer, device, num_epochs=epochs, points_used = num_inputs, num_query_points=num_query_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), \"klautoencoder.pth\")\n",
    "\n",
    "# load model\n",
    "# model = layers.KLAutoEncoder(num_inputs=num_inputs, num_latents=num_latents, dim = dim).to(device)\n",
    "# model.load_state_dict(torch.load(\"klautoencoder.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f6c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def test_model(example, num_query = 10000):\n",
    "    B, N, D = example.shape\n",
    "    \n",
    "    \"\"\" Sample from point clouds in the example \"\"\" # (each example contains multiple point clouds)\n",
    "    ### input points ###\n",
    "    sample_pos = torch.zeros((B, num_inputs, 3), device=device) # shape [B, num_inputs, 3] - surface points sampled from each shape in the example\n",
    "\n",
    "    for i in range(B):\n",
    "        shape = example[i]  # [N, 4]\n",
    "        surface_pts = shape[shape[:, 3] == 0]  # sdf == 0 â†’ surface points\n",
    "        # Random sample\n",
    "        sample_idx = torch.randperm(surface_pts.shape[0])[:num_inputs]\n",
    "        sample_pos[i] = surface_pts[sample_idx, :3]  # only x,y,z\n",
    "    \n",
    "    ### query points ###\n",
    "    querys_idx = torch.randint(0, N, (B, num_query), device=example.device) # dim = (B, num_query)\n",
    "    query_idx = torch.arange(B, device=example.device).unsqueeze(1).expand(-1, num_query) # [B, num_query]\n",
    "    # use advanced indexing to gather the sampled points\n",
    "    query_points = example[query_idx, querys_idx] # [B, query_points, 4]\n",
    "    query_pos = query_points[:, :, :3].to(device) # [B, num_inputs, 3]\n",
    "    query_sdf = query_points[:, :, 3].to(device)   # shape [B, query_points]\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    outputs = model(sample_pos, query_pos)\n",
    "    sdf_values = outputs['sdf'].unsqueeze(-1)\n",
    "\n",
    "    combined = torch.cat([query_pos, sdf_values], dim=-1)[0]  # return only result for first shape\n",
    "    return combined\n",
    "\n",
    "def totally_random(example):\n",
    "    shape0 = example[0]\n",
    "    query_idx = torch.randperm(shape0.shape[0])[:10000]\n",
    "    queries = shape0[query_idx].unsqueeze(0) # [1, 2048, 4]\n",
    "    query_pos = queries[:, :, :3].to(device) # [B, num_inputs, 3]\n",
    "    sdf_values = torch.rand(1, 10000, 1) - 0.15\n",
    "    combined = torch.cat([query_pos.cpu(), sdf_values.cpu()], dim=-1)  # shape [1, 512, 4]\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51b6c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\OneDrive - Yale University\\Personal\\Studies\\Semester 4\\CPSC 452\\Project\\Repo\\CPSC-452-Final-Project\\dataset_utils.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(os.path.join(self.path, self.files[idx]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled_pc_embeddings shape: torch.Size([1, 512, 512]), pc_embeddings shape: torch.Size([1, 2048, 512])\n",
      "TRUE\n"
     ]
    }
   ],
   "source": [
    "import dataset_utils\n",
    "model.eval()\n",
    "example = next(iter(train_loader))\n",
    "print(example.shape)\n",
    "pred = test_model(example).squeeze(0).cpu()\n",
    "rand = totally_random(example).squeeze(0)\n",
    "\n",
    "# dataset_utils.visualize_sdf_2d(pred.detach().cpu())\n",
    "print(\"TRUE\")\n",
    "example = example[0]\n",
    "dataset_utils.visualize_sdf_3d(example)\n",
    "dataset_utils.visualize_sdf_2d(example)\n",
    "print(\"MODEL\")\n",
    "dataset_utils.visualize_sdf_3d(pred.detach().cpu())\n",
    "dataset_utils.visualize_sdf_2d(pred.detach().cpu(), tolerance=0.1)\n",
    "print(\"TOTALLY RANDOM\")\n",
    "dataset_utils.visualize_sdf_3d(rand)\n",
    "dataset_utils.visualize_sdf_2d(rand)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
